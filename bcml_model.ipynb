{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bcml_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bcml_model\n",
    "\n",
    "> Core class representing a binary classification (BC) machine learning (ML) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm\n",
    "import scipy.interpolate\n",
    "import scipy.optimize\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class bcml_model:\n",
    "    \"\"\"\n",
    "    Represents a machine learning (ML) binary classification (BC) model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, preds, labels):\n",
    "        r\"\"\" \n",
    "        Fits `model` to data.\n",
    "        \n",
    "        `preds` should be ? $\\times$ $m$ for model with $m$ features. `labels` should\n",
    "        be ? $\\times$ 1 and take values in $\\{0,1\\}$.\n",
    "        \"\"\"\n",
    "        self.model.fit(preds, labels)\n",
    "        \n",
    "    def predict_proba(self, preds):\n",
    "        r\"\"\"\n",
    "        Predicts signal probability for each element of a dataset ($? \\times m$ `numpy` array).\n",
    "        \n",
    "        Returns `numpy` array of with values in $[0,1]$ giving predicted signal probabilities for\n",
    "        each data point.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.model.predict_proba(preds)[:,1]\n",
    "        except:\n",
    "            print(\"self.model doesn't have a predict_proba function\")\n",
    "            \n",
    "    def predict(self, preds, threshold=None):\n",
    "        r\"\"\"\n",
    "        Predicts signal ($1$) or background ($0$) for each element of a dataset ($? \\times m$ `numpy` array).\n",
    "        \n",
    "        Returns `numpy` array of length with values in $\\{0,1\\}$ giving predicted classifications. \n",
    "        \n",
    "        Uses the `predict` method built into `scikit-learn` models.\n",
    "        \"\"\"\n",
    "        if threshold is not None:\n",
    "            probs = self.model.predict_proba(preds)[:,1]\n",
    "            return np.where(probs > threshold, np.ones_like(probs), np.zeros_like(probs))\n",
    "        else:\n",
    "            try:\n",
    "                return self.model.predict(preds)\n",
    "            except:\n",
    "                print(\"self.model doesn't have a predict function\")\n",
    "                \n",
    "    def predict_hist(self, preds, labels, num_bins=100, sepbg=False, sig_norm=1, bg_norm=1, dataframe=False):\n",
    "        r\"\"\"\n",
    "        Constructs a histogram of predicted signal probabilities for signal and background constituents of \n",
    "        a dataset ($? \\times M$ `numpy` array).\n",
    "        \n",
    "        If `sepbg` is `False` (the default), labels are assumed to take values in $\\{0,1\\}$. Backgrounds are treated in combination:\n",
    "        a list of $3$ $?_i \\times m$ `numpy` arrays are returned, containing bin edges (partitioning $[0,1]$), \n",
    "        signal bin contents, and background bin contents.\n",
    "        \n",
    "        If `sepbg` is `True`, labels are assumed to take values in $\\{-n,\\dots,-1,1\\}$ (if there are $n$ backgrounds) while\n",
    "        `bg_norm` should be a list of length $n$. Backgrounds are then differentiated: a list of $2 + n$ `numpy` arrays of shape\n",
    "        $?_i \\times m$ are returned, containing bin edges (partitioning $[0,1]$), signal bin contents, and \n",
    "        $n$ background bin contents.\n",
    "        \"\"\"\n",
    "        predictions = self.predict_proba(preds)\n",
    "        sig_bins, bin_edges = np.histogram(predictions[labels==1], bins=num_bins, density=True)\n",
    "        sig_bins *= sig_norm\n",
    "        if sepbg:\n",
    "            bg_norms = bg_norm\n",
    "            bg_binss = [\n",
    "                bg_norm * np.histogram(predictions[labels==-(i+1)], bins=num_bins, density=True)[0]\n",
    "                for i, bg_norm in enumerate(bg_norms)]\n",
    "            if dataframe:\n",
    "                return pd.DataFrame(data=[bin_edges, sig_bins] + bg_binss, columns=['Bin Edges', 'Signal'] + ['Background {}'.format(i) for i in range(1, self.num_bgs+1)])\n",
    "            else:\n",
    "                return [bin_edges, sig_bins] + bg_binss\n",
    "        else:\n",
    "            bg_bins = np.histogram(predictions[labels!=1], bins=num_bins, density=True)[0]\n",
    "            if dataframe:\n",
    "                return pd.DataFrame(data=[bin_edges, sig_bins, bg_bins], columns=['Bin Edges', 'Signal', 'Background'])\n",
    "            else:\n",
    "                return [bin_edges, sig_bins, bg_bins]\n",
    "            \n",
    "    def feature_importance(self):\n",
    "        \"\"\"\n",
    "        Returns the importance of the $M$ features used to train `self.model`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.model.feature_importances_\n",
    "        except:\n",
    "            try:\n",
    "                return self.model[-1].feature_importances_\n",
    "            except:\n",
    "                print(\"It looks like self.model doesn't have an attribute 'feature_importances_'\")\n",
    "    \n",
    "    def sorted_feature_importance(self, features):\n",
    "        r\"\"\"\n",
    "        Returns list of features sorted by importance.\n",
    "        \n",
    "        Given arguments `features` and `importances`, lists of length $M$, returns list of size $M \\times 2$ where\n",
    "        the first column gives features and the second their associated importances, sorted by importance.\n",
    "        \"\"\"\n",
    "        importances = self.feature_importance()\n",
    "        ranked_indices = np.argsort(-np.abs(importances))\n",
    "        return [[features[i], importances[i]] for i in ranked_indices]\n",
    "        \n",
    "    def accuracy(self, preds, labels, threshold=None):\n",
    "        r\"\"\"\n",
    "        Computes model accuracy on a dataset ($? x m$ predictors, length $?$ labels).\n",
    "        \n",
    "        Returns value in $[0,1]$ giving model accuracy on the provided predictors and labels.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(preds=preds, threshold=threshold)\n",
    "        return len(preds) - np.sum(np.abs(predictions - labels)) / len(preds)\n",
    "        \n",
    "    def conf_matrix(self, labels, predictions=None, preds=None):\n",
    "        r\"\"\"\n",
    "        Computes the confusion matrix of the trained model on a dataset ($? x M$ predictors, length $?$ labels).\n",
    "        \n",
    "        Returns $2 \\times 2$ confusion matrix using `sklearn.metrics.confusion_matrix`.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        if predictions is not None:\n",
    "            return skm.confusion_matrix(labels, predictions, labels=[0,1])\n",
    "        elif preds is not None:\n",
    "            return skm.confusion_matrix(labels, self.predict(preds), labels=[0,1])\n",
    "        else:\n",
    "            raise ValueError('Either predictions or preds must be passed.')\n",
    "        \n",
    "    \n",
    "    def tpr_cm(self, conf_matrix):\n",
    "        \"\"\"\n",
    "        Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
    "        of a trained model given a confusion matrix.\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return conf_matrix[1,1]/np.sum(conf_matrix[1])\n",
    "        \n",
    "    def fpr_cm(self, conf_matrix):\n",
    "        \"\"\"\n",
    "        Computes the false positive rate (fpr; misidentified background/total background) \n",
    "        of a trained model given a confusion matrix.\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return conf_matrix[0,1]/np.sum(conf_matrix[0])\n",
    "    \n",
    "    def tpr(self, labels, predictions=None, preds=None):\n",
    "        r\"\"\"\n",
    "        Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
    "        of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return self.tpr_cm(self.conf_matrix(labels, predictions=predictions, preds=preds))\n",
    "    \n",
    "    def fpr(self, labels, predictions=None, preds=None):\n",
    "        r\"\"\"\n",
    "        Computes the false positive rate (fpr; misidentified background/total background) \n",
    "        of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return self.fpr_cm(self.conf_matrix(labels, predictions=predictions, preds=preds))\n",
    "    \n",
    "    def significance(self, signal, background, tpr, fpr, sepbg=False):\n",
    "        r\"\"\"\n",
    "        Computes signal significance of a trained model given signal and background yield.\n",
    "        \n",
    "        Returns a positive real number computed by \n",
    "        $$\\frac{S \\cdot TPR}{\\sqrt{S \\cdot TPR + B \\cdot FPR}}$$\n",
    "        which corresponds to signal significance after selecting only datapoints the model identifies as signal.\n",
    "        \n",
    "        If `sepbg` is `False`, `background` should be a single real number and is multiplied by `fpr`. If `sepbg` is `True`,\n",
    "        `background` should be a list of length `self.num_bgs` where the $i$th element contains background yield of the $i$th\n",
    "        background type. `fpr`, if passed, is then also a list of length `self.num_bgs` giving false positive rates for each\n",
    "        of the background types.\n",
    "        \"\"\"\n",
    "        if sepbg:\n",
    "            backgrounds = background\n",
    "            fprs = fpr\n",
    "            fprXbackground = np.sum(np.multiply(fprs, backgrounds), axis=-1)\n",
    "            return (signal * tpr) / np.sqrt(signal * tpr + fprXbackground + 1e-10)\n",
    "        else:\n",
    "            return (signal * tpr) / np.sqrt(signal * tpr + background * fpr + 1e-10)\n",
    "    \n",
    "    def newvar2thresh(self, newvar):\n",
    "        r\"\"\"\n",
    "        Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
    "        performing change of variables from `newvar` to `threshold`\n",
    "        \n",
    "        In particular, threshold $= 1 - 10^{\\text{newvar}}$\n",
    "        \"\"\"\n",
    "        return 1 - np.power(10, newvar)\n",
    "    \n",
    "    def thresh2newvar(self, thresh):\n",
    "        r\"\"\"\n",
    "        Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
    "        performing change of variables from `threshold` to `newvar`\n",
    "        \n",
    "        In particular, newvar $= \\log_{10}(1 - \\text{threhold})$\n",
    "        \"\"\"\n",
    "        return np.log10(1 - thresh)\n",
    "    \n",
    "    def max_allowable_threshold(self, preds, labels):\n",
    "        \"\"\"\n",
    "        Returns the highest threshold such that only labelling elements of `self.test_pred` with predicted\n",
    "        probabilities higher than that threshold as signal still yields 25 signal.\n",
    "        \n",
    "        To achieve a discovery potential of $5\\sigma$, even in the best case scenario ($TPR = 1, FPR = 0$) we still\n",
    "        require $5^2 = 25$ signal events, hence we cannot chose a threshold so high that we do not keep at least\n",
    "        25 signal events.\n",
    "        \n",
    "        NOTE: this function frequently returns an extrapolation error as $25$ frequently falls outside of the \n",
    "        function interpolation range (i.e., to achieve less than 25 signal events requires coming extremely close to $1$).\n",
    "        \"\"\"\n",
    "        newvars = np.concatenate((np.linspace(-8, -2, 10, endpoint=False), np.linspace(-2, 0, 51, endpoint=False)))\n",
    "        probs = self.model.predict_proba(preds)[:,1]\n",
    "        predicts = np.array(\n",
    "            [np.where(probs > self.newvar2thresh(newvar),\n",
    "                      np.ones_like(probs), np.zeros_like(probs)) for newvar in newvars])\n",
    "        num_sig = [np.sum(predict[(predict == 1) & (labels == 1)]) for predict in predicts]\n",
    "        f = scipy.interpolate.interp1d(num_sig, newvars, kind='cubic')\n",
    "        return self.newvar2thresh(f(25))\n",
    "    \n",
    "    def get_tprs_fprs(self, preds, labels, sepbg=False):\n",
    "        \"\"\"\n",
    "        Produces (true positive rate, false positive rate) pairs for various thresholds \n",
    "        for the trained model on data sets.\n",
    "        \n",
    "        If `sepbg` is `True`, labels should take values in $\\{-n,\\dots,-1,1\\}$. Background is combined and a list of length $4$ \n",
    "        is returned containing a list of $L$ sampled newvars (a convenient change of variable to approach arbitrarily close to 1: \n",
    "        related to thresholds by  `bcml_model.newvar2thresh()`), an $L$-list of tprs associated to those thresholds, an $L$-list of fprs \n",
    "        related to those thresholds, and an $L$-list of length $?$ `numpy` arrays giving the predicted signal probabilities\n",
    "        for the given data set.\n",
    "        \n",
    "        If `sepbg` is `Frue`, labels should take values in $\\{0,1\\}$. Background is split and a list of length $4$ `self.num_bgs` \n",
    "        is returned containing a  list of $L$ sampled newvars, an $L$-list of tprs associated to those thresholds, an $L$-list of lists of length\n",
    "        $n$ (number of backgrounds) containing fprs for each background type for each threshold, and an $L$-list of length $?$ \n",
    "        \"\"\"\n",
    "        # setting up variables\n",
    "        min_newvar, max_newvar = [-10, 0]\n",
    "        newvars = np.concatenate((np.linspace(min_newvar, -2, 10, endpoint=False), np.linspace(-2, max_newvar, 15, endpoint=False)))\n",
    "        \n",
    "        # computing tprs, fprs\n",
    "        if sepbg:\n",
    "            num_bgs = len(np.unique(labels)) - 1\n",
    "            labelTypes = [1] + [-(i+1) for i in range(num_bgs)]\n",
    "            labelsIndices = [np.where(labels==i)[0] for i in labelTypes]\n",
    "            predss = [preds[indices] for indices in labelsIndices]\n",
    "            probss = [self.predict_proba(preds) for preds in predss]\n",
    "            predictionsss = np.array(\n",
    "                [[np.where(probs > self.newvar2thresh(newvar), \n",
    "                          np.ones_like(probs), np.zeros_like(probs)) for probs in probss] for newvar in newvars])\n",
    "            sig_conf_matrices = [\n",
    "                self.conf_matrix(labels=np.ones_like(predictionss[0]), predictions=predictionss[0]) for predictionss in predictionsss]\n",
    "            bg_conf_matricess = [\n",
    "                [self.conf_matrix(labels=np.zeros_like(predictions), predictions=predictions) for i, predictions in enumerate(predictionss[1:])] for predictionss in predictionsss]\n",
    "            tprs = np.array([self.tpr_cm(conf_matrix) for conf_matrix in sig_conf_matrices])\n",
    "            fprss = np.array([[self.fpr_cm(conf_matrix) for conf_matrix in conf_matrices] for conf_matrices in bg_conf_matricess])\n",
    "            sums = tprs + np.sum(fprss, axis=1)\n",
    "            cutoff = len(sums) - np.argmax(np.flip(sums)==0) + 1 if 0 in sums else 0\n",
    "            return [newvars[cutoff:], tprs[cutoff:], fprss[cutoff:], probss]\n",
    "        else:\n",
    "            probs = self.predict_proba(preds)\n",
    "            predictionss = np.array(\n",
    "                [np.where(probs > self.newvar2thresh(newvar), \n",
    "                          np.ones_like(probs), np.zeros_like(probs)) for newvar in newvars])\n",
    "            conf_matrices = [self.conf_matrix(labels=labels, predictions=predictions) for predictions in predictionss]\n",
    "            tprs = np.array([self.tpr_cm(conf_matrix) for conf_matrix in conf_matrices])\n",
    "            fprs = np.array([self.fpr_cm(conf_matrix) for conf_matrix in conf_matrices])\n",
    "            sums = tprs + fprs\n",
    "            cutoff = len(sums) - np.argmax(np.flip(sums)==0) + 1 if 0 in sums else 0\n",
    "            return [newvars[cutoff:], tprs[cutoff:], fprs[cutoff:], probs]\n",
    "        \n",
    "    def best_threshold(self, signal, background, preds, labels, sepbg=False):\n",
    "        \"\"\"\n",
    "        Optimizes the threshold on a given data set ($? x M$ predictors, length $?$ labels).\n",
    "        \"\"\"\n",
    "        newvars, tprs, fprs, probs = self.get_tprs_fprs(preds, labels, sepbg)\n",
    "        significances = -self.significance(signal, background, tprs, fprs, sepbg=sepbg)\n",
    "\n",
    "        # interpolating significance as a function of threshold, then maximizing\n",
    "        max_sig = np.amin(significances)\n",
    "        significances_list = list(significances)\n",
    "        i = significances_list.index(max_sig)\n",
    "        min_i, max_i = [max(0,i-4),min(len(significances),i+5)]\n",
    "        f = scipy.interpolate.interp1d(newvars[min_i:max_i], significances[min_i:max_i], kind='cubic')\n",
    "        res = scipy.optimize.minimize(f, [0.5 * (newvars[min_i] + newvars[max_i-1])], bounds=[(newvars[min_i] + 1e-1, newvars[max_i-1] - 1e-1)])\n",
    "        \n",
    "        # computing significance, tpr, fpr for optimized threshold\n",
    "        best_threshold = self.newvar2thresh(res.x[0])\n",
    "        if sepbg:\n",
    "            probss = probs\n",
    "            fprss = fprs\n",
    "            best_predictss = [np.where(probs > best_threshold, np.ones_like(probs), np.zeros_like(probs)) for probs in probss]\n",
    "            sig_conf_matrix = self.conf_matrix(labels=np.ones_like(best_predictss[0]), predictions=best_predictss[0])\n",
    "            bg_conf_matrices = [self.conf_matrix(labels=np.zeros_like(best_predicts), predictions=best_predicts) for i, best_predicts in enumerate(best_predictss[1:])]\n",
    "            tpr = self.tpr_cm(sig_conf_matrix)\n",
    "            fprs = [self.fpr_cm(conf_matrix) for conf_matrix in bg_conf_matrices]\n",
    "            best_sig = self.significance(signal, background, tpr, fprs, sepbg=sepbg)\n",
    "            return [best_threshold, best_sig, tpr, fprs, tprs, fprss]\n",
    "        else:\n",
    "            best_predicts = np.where(probs > best_threshold, np.ones_like(probs), np.zeros_like(probs))\n",
    "            conf_matrix = self.conf_matrix(labels=labels, predictions=best_predicts)\n",
    "            tpr = self.tpr_cm(conf_matrix)\n",
    "            fpr = self.fpr_cm(conf_matrix)\n",
    "            best_sig = self.significance(signal, background, tpr, fpr, sepbg=sepbg)\n",
    "            return [best_threshold, best_sig, tpr, fpr, tprs, fprs]\n",
    "    \n",
    "    def req_sig_cs(self, lumi, bg_cs, tpr, fpr, sig=5, sepbg=False):\n",
    "        \"\"\"\n",
    "        Given a luminosity (in fb$^{-1}$), a background cross section (in pb), a true positive rate, a false positive rate,\n",
    "        and a signal significance, computes the signal cross section required for the signal significance to be achieved.\n",
    "        \n",
    "        If `sepbg` is False, background is combined and a single FPR is used; if `sepbg` is True, it is assumed that\n",
    "        `bg_cs`, `fpr` are each lists of length $n$ (number of backgrounds) and their vector dot product is used for background yield.\n",
    "        \"\"\"\n",
    "        conv = 10**15 / 10**12\n",
    "        if sepbg:\n",
    "            bg = np.sum(np.multiply(bg_cs, fpr))\n",
    "            coef = [-tpr**2 * lumi * conv**2, sig**2 * tpr * conv, sig**2 * bg * conv]\n",
    "        else:\n",
    "            coef = [-tpr**2 * lumi * conv**2, sig**2 * tpr * conv, sig**2 * fpr * bg_cs * conv]\n",
    "        return np.amax(np.roots(coef))\n",
    "        \n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the model to `filename.joblib`\n",
    "        \"\"\"\n",
    "        joblib.dump(self.model, filename + '.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting up and running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a `bcml_model` instance\n",
    "\n",
    "To create a new `bcml_model` instance, all you need to pass is a `model`, a machine learning binary classification model. This library was designed to work with `scikit-learn` classifiers, such as `sklearn.linear_model.LogisticRegression`, `sklearn.ensemble.RandomForestClassifier`, or `sklearn.ensemble.GradientBoostingClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fit\" class=\"doc_header\"><code>bcml_model.fit</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fit</code>(**`preds`**, **`labels`**)\n",
       "\n",
       "Fits `model` to data.\n",
       "\n",
       "`preds` should be ? $\\times$ $m$ for model with $m$ features. `labels` should\n",
       "be ? $\\times$ 1 and take values in $\\{0,1\\}$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict_proba\" class=\"doc_header\"><code>bcml_model.predict_proba</code><a href=\"__main__.py#L31\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict_proba</code>(**`preds`**)\n",
       "\n",
       "Predicts signal probability for each element of a dataset ($? \\times m$ `numpy` array).\n",
       "\n",
       "Returns `numpy` array of with values in $[0,1]$ giving predicted signal probabilities for\n",
       "each data point."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict\" class=\"doc_header\"><code>bcml_model.predict</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict</code>(**`preds`**, **`threshold`**=*`None`*)\n",
       "\n",
       "Predicts signal ($1$) or background ($0$) for each element of a dataset ($? \\times m$ `numpy` array).\n",
       "\n",
       "Returns `numpy` array of length with values in $\\{0,1\\}$ giving predicted classifications. \n",
       "\n",
       "Uses the `predict` method built into `scikit-learn` models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict_hist\" class=\"doc_header\"><code>bcml_model.predict_hist</code><a href=\"__main__.py#L60\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict_hist</code>(**`preds`**, **`labels`**, **`num_bins`**=*`100`*, **`sepbg`**=*`False`*, **`sig_norm`**=*`1`*, **`bg_norm`**=*`1`*, **`dataframe`**=*`False`*)\n",
       "\n",
       "Constructs a histogram of predicted signal probabilities for signal and background constituents of \n",
       "a dataset ($? \\times M$ `numpy` array).\n",
       "\n",
       "If `sepbg` is `False` (the default), labels are assumed to take values in $\\{0,1\\}$. Backgrounds are treated in combination:\n",
       "a list of $3$ $?_i \\times m$ `numpy` arrays are returned, containing bin edges (partitioning $[0,1]$), \n",
       "signal bin contents, and background bin contents.\n",
       "\n",
       "If `sepbg` is `True`, labels are assumed to take values in $\\{-n,\\dots,-1,1\\}$ (if there are $n$ backgrounds) while\n",
       "`bg_norm` should be a list of length $n$. Backgrounds are then differentiated: a list of $2 + n$ `numpy` arrays of shape\n",
       "$?_i \\times m$ are returned, containing bin edges (partitioning $[0,1]$), signal bin contents, and \n",
       "`self.num_bgs` background bin contents."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.feature_importance\" class=\"doc_header\"><code>bcml_model.feature_importance</code><a href=\"__main__.py#L93\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.feature_importance</code>()\n",
       "\n",
       "Returns the importance of the $M$ features used to train `self.model`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.sorted_feature_importance\" class=\"doc_header\"><code>bcml_model.sorted_feature_importance</code><a href=\"__main__.py#L105\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.sorted_feature_importance</code>(**`features`**)\n",
       "\n",
       "Returns list of features sorted by importance.\n",
       "\n",
       "Given arguments `features` and `importances`, lists of length $M$, returns list of size $M \\times 2$ where\n",
       "the first column gives features and the second their associated importances, sorted by importance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.sorted_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.accuracy\" class=\"doc_header\"><code>bcml_model.accuracy</code><a href=\"__main__.py#L116\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.accuracy</code>(**`preds`**, **`labels`**, **`threshold`**=*`None`*)\n",
       "\n",
       "Computes model accuracy on a dataset ($? x m$ predictors, length $?$ labels).\n",
       "\n",
       "Returns value in $[0,1]$ giving model accuracy on the provided predictors and labels."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.conf_matrix\" class=\"doc_header\"><code>bcml_model.conf_matrix</code><a href=\"__main__.py#L125\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.conf_matrix</code>(**`labels`**, **`predictions`**=*`None`*, **`preds`**=*`None`*)\n",
       "\n",
       "Computes the confusion matrix of the trained model on a dataset ($? x M$ predictors, length $?$ labels).\n",
       "\n",
       "Returns $2 \\times 2$ confusion matrix using `sklearn.metrics.confusion_matrix`.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.tpr_cm\" class=\"doc_header\"><code>bcml_model.tpr_cm</code><a href=\"__main__.py#L142\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.tpr_cm</code>(**`conf_matrix`**)\n",
       "\n",
       "Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
       "of a trained model given a confusion matrix.\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.tpr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fpr_cm\" class=\"doc_header\"><code>bcml_model.fpr_cm</code><a href=\"__main__.py#L151\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fpr_cm</code>(**`conf_matrix`**)\n",
       "\n",
       "Computes the false positive rate (fpr; misidentified background/total background) \n",
       "of a trained model given a confusion matrix.\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fpr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.tpr\" class=\"doc_header\"><code>bcml_model.tpr</code><a href=\"__main__.py#L160\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.tpr</code>(**`predictions`**, **`labels`**)\n",
       "\n",
       "Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
       "of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fpr\" class=\"doc_header\"><code>bcml_model.fpr</code><a href=\"__main__.py#L169\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fpr</code>(**`predictions`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Computes the false positive rate (fpr; misidentified background/total background) \n",
       "of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenomenology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.significance\" class=\"doc_header\"><code>bcml_model.significance</code><a href=\"__main__.py#L178\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.significance</code>(**`signal`**, **`background`**, **`tpr`**, **`fpr`**, **`sepbg`**=*`False`*)\n",
       "\n",
       "Computes signal significance of a trained model given signal and background yield.\n",
       "\n",
       "Returns a positive real number computed by \n",
       "$$\\frac{S \\cdot TPR}{\\sqrt{S \\cdot TPR + B \\cdot FPR}}$$\n",
       "which corresponds to signal significance after selecting only datapoints the model identifies as signal.\n",
       "\n",
       "If `sepbg` is `False`, `background` should be a single real number and is multiplied by `fpr`. If `sepbg` is `True`,\n",
       "`background` should be a list of length `self.num_bgs` where the $i$th element contains background yield of the $i$th\n",
       "background type. `fpr`, if passed, is then also a list of length `self.num_bgs` giving false positive rates for each\n",
       "of the background types."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.newvar2thresh\" class=\"doc_header\"><code>bcml_model.newvar2thresh</code><a href=\"__main__.py#L199\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.newvar2thresh</code>(**`newvar`**)\n",
       "\n",
       "Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
       "performing change of variables from `newvar` to `threshold`\n",
       "\n",
       "In particular, threshold $= 1 - 10^{\\text{newvar}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.newvar2thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.thresh2newvar\" class=\"doc_header\"><code>bcml_model.thresh2newvar</code><a href=\"__main__.py#L208\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.thresh2newvar</code>(**`thresh`**)\n",
       "\n",
       "Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
       "performing change of variables from `threshold` to `newvar`\n",
       "\n",
       "In particular, newvar $= \\log_{10}(1 - \\text{threhold})$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.thresh2newvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.max_allowable_threshold\" class=\"doc_header\"><code>bcml_model.max_allowable_threshold</code><a href=\"__main__.py#L217\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.max_allowable_threshold</code>(**`preds`**, **`labels`**)\n",
       "\n",
       "Returns the highest threshold such that only labelling elements of `self.test_pred` with predicted\n",
       "probabilities higher than that threshold as signal still yields 25 signal.\n",
       "\n",
       "To achieve a discovery potential of $5\\sigma$, even in the best case scenario ($TPR = 1, FPR = 0$) we still\n",
       "require $5^2 = 25$ signal events, hence we cannot chose a threshold so high that we do not keep at least\n",
       "25 signal events.\n",
       "\n",
       "NOTE: this function frequently returns an extrapolation error as $25$ frequently falls outside of the \n",
       "function interpolation range (i.e., to achieve less than 25 signal events requires coming extremely close to $1$)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.max_allowable_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.get_tprs_fprs\" class=\"doc_header\"><code>bcml_model.get_tprs_fprs</code><a href=\"__main__.py#L238\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.get_tprs_fprs</code>(**`preds`**, **`labels`**, **`sepbg`**=*`False`*)\n",
       "\n",
       "Produces (true positive rate, false positive rate) pairs for various thresholds \n",
       "for the trained model on data sets.\n",
       "\n",
       "If `sepbg` is `True`, labels should take values in $\\{-n,\\dots,-1,1\\}$. Background is combined and a list of length $4$ \n",
       "is returned containing a list of $L$ sampled newvars (a convenient change of variable to approach arbitrarily close to 1: \n",
       "related to thresholds by  [`bcml_model.newvar2thresh()`](/bcml4pheno/bcml_model.html#bcml_model.newvar2thresh())), an $L$-list of tprs associated to those thresholds, an $L$-list of fprs \n",
       "related to those thresholds, and an $L$-list of length $?$ `numpy` arrays giving the predicted signal probabilities\n",
       "for the given data set.\n",
       "\n",
       "If `sepbg` is `Frue`, labels should take values in $\\{0,1\\}$. Background is split and a list of length $4$ `self.num_bgs` \n",
       "is returned containing a  list of $L$ sampled newvars, an $L$-list of tprs associated to those thresholds, an $L$-list of lists of length\n",
       "$n$ (number of backgrounds) containing fprs for each background type for each threshold, and an $L$-list of length $?$ "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.get_tprs_fprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.best_threshold\" class=\"doc_header\"><code>bcml_model.best_threshold</code><a href=\"__main__.py#L291\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.best_threshold</code>(**`signal`**, **`background`**, **`preds`**, **`labels`**, **`sepbg`**=*`False`*)\n",
       "\n",
       "Optimizes the threshold on a given data set ($? x M$ predictors, length $?$ labels)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.req_sig_cs\" class=\"doc_header\"><code>bcml_model.req_sig_cs</code><a href=\"__main__.py#L327\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.req_sig_cs</code>(**`lumi`**, **`bg_cs`**, **`tpr`**, **`fpr`**, **`sig`**=*`5`*, **`sepbg`**=*`False`*)\n",
       "\n",
       "Given a luminosity (in fb$^{-1}$), a background cross section (in pb), a true positive rate, a false positive rate,\n",
       "and a signal significance, computes the signal cross section required for the signal significance to be achieved.\n",
       "\n",
       "If `sepbg` is False, background is combined and a single FPR is used; if `sepbg` is True, it is assumed that\n",
       "`bg_cs`, `fpr` are each lists of length $n$ (number of backgrounds) and their vector dot product is used for background yield."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.req_sig_cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula used by `req_sig_cs` arises as follows.\n",
    "\n",
    "We know that\n",
    "$$\\mathcal{S} = \\frac{S \\cdot \\text{TPR}}{\\sqrt{S \\cdot \\text{TPR} + B \\cdot \\text{FPR}}} = \\frac{\\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR}}{\\sqrt{\\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR} + \\mathcal{L} \\cdot \\sigma_s \\cdot \\text{FPR}}}$$\n",
    "We can work toward solving for $\\sigma_s$ as follows.\n",
    "\\begin{align}\n",
    "    \\mathcal{S} &= \\frac{\\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR}}{\\sqrt{\\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR} + \\mathcal{L} \\cdot \\sigma_b \\cdot \\text{FPR}}} \\\\\n",
    "    \\mathcal{S} \\left(\\sqrt{\\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR} + \\mathcal{L} \\cdot \\sigma_b \\cdot \\text{FPR}}\\right)&= \\mathcal{L} \\cdot \\sigma_s \\cdot \\text{TPR} \\\\\n",
    "    \\mathcal{S}^2 \\left(\\sigma_s \\cdot \\text{TPR} + \\sigma_b \\cdot \\text{FPR}\\right) &= \\mathcal{L} \\cdot \\sigma_s^2 \\cdot \\text{TPR}^2 \\\\\n",
    "    0 &= -\\left(\\mathcal{L} \\cdot \\text{TPR}^2\\right)\\sigma_s^2 + \\left(\\mathcal{S}^2 \\cdot \\text{TPR}\\right)\\sigma_s + \\left(\\mathcal{S}^2 \\cdot \\sigma_b \\cdot \\text{FPR}\\right)\n",
    "\\end{align}\n",
    "This is then easily solvable using the quadratic formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.save_model\" class=\"doc_header\"><code>bcml_model.save_model</code><a href=\"__main__.py#L343\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.save_model</code>(**`filename`**)\n",
       "\n",
       "Saves the model to `filename.joblib`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def refresh_model(model):\n",
    "        \"\"\"\n",
    "        If this class gets updated, run this function on your already trained model to have it reflect the updated\n",
    "        class without retraining being necessary.\n",
    "        \"\"\"\n",
    "        return bcml_model(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
