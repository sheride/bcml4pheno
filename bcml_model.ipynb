{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bcml_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bcml_model\n",
    "\n",
    "> Core class representing a binary classification (BC) machine learning (ML) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm\n",
    "import scipy.interpolate\n",
    "import scipy.optimize\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class bcml_model:\n",
    "    \"\"\"\n",
    "    Represents a machine learning (ML) binary classification (BC) model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, train, test, num_bgs=3):\n",
    "        self.model = model\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.num_bgs = num_bgs\n",
    "        self.train_preds = train[:,:-1]\n",
    "        self.train_labels = np.where(train[:,-1]==1, np.ones_like(train[:,-1]), np.zeros_like(train[:,-1]))\n",
    "        self.test_preds = test[:,:-1]\n",
    "        self.test_labels = np.where(test[:,-1]==1, np.ones_like(test[:,-1]), np.zeros_like(test[:,-1]))\n",
    "        self.test_bgs = [self.test[self.test[:,-1] == -i] for i in range(1,self.num_bgs+1)]\n",
    "        self.test_bgs_preds = [data[:,:-1] for data in self.test_bgs]\n",
    "        self.test_sigs = self.test[self.test[:,-1] == 1]\n",
    "        self.test_sigs_preds = self.test_sigs[:,:-1]\n",
    "    \n",
    "    def fit(self, preds=None, labels=None):\n",
    "        \"\"\" \n",
    "        Fits `model` to data.\n",
    "        \n",
    "        If predictors `preds` and labels `labels` aren't provided, \n",
    "        `self.train_preds` and `self.train_labels` are used, respectively.\n",
    "        \"\"\"\n",
    "        preds = preds if preds is not None else self.train_preds\n",
    "        labels = labels if labels is not None else self.train_labels\n",
    "        self.model.fit(preds, labels)\n",
    "        \n",
    "    def predict_proba(self, preds=None):\n",
    "        r\"\"\"\n",
    "        Predicts signal probability for each element of a dataset ($? \\times M$ `numpy` array).\n",
    "        \n",
    "        Returns `numpy` array of length $M$ with values in $[0,1]$ giving predicted signal probabilities.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        Uses the `predict_proba` method built into `scikit-learn` models.\n",
    "        \"\"\"\n",
    "        preds = preds if preds is not None else self.test_preds\n",
    "        try:\n",
    "            return self.model.predict_proba(preds)[:,1]\n",
    "        except:\n",
    "            print(\"self.model doesn't have a predict_proba function\")\n",
    "            \n",
    "    def predict(self, preds=None, threshold=None):\n",
    "        \"\"\"\n",
    "        Predicts signal ($1$) or background ($2$) for each element of a dataset ($? \\times M$ `numpy` array).\n",
    "        \n",
    "        Returns `numpy` array of length $M$ with values in $\\{0,1\\}$ giving predicted classifications. \n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used.\n",
    "        Uses the `predict` method built into `scikit-learn` models.\n",
    "        \"\"\"\n",
    "        preds = preds if preds is not None else self.test_preds\n",
    "        if threshold is not None:\n",
    "            probs = self.model.predict_proba(preds)[:,1]\n",
    "            return np.where(probs > threshold, np.ones_like(probs), np.zeros_like(probs))\n",
    "        else:\n",
    "            try:\n",
    "                return self.model.predict(preds)\n",
    "            except:\n",
    "                print(\"self.model doesn't have a predict function\")\n",
    "                \n",
    "    def predict_hist(self, preds=None, labels=None, num_bins=100, sepbg=False, sig_norm=1, bg_norm=1, dataframe=False):\n",
    "        r\"\"\"\n",
    "        Constructs a histogram of predicted signal probabilities for signal and background constituents of \n",
    "        a dataset ($? \\times M$ `numpy` array).\n",
    "        \n",
    "        If `sepbg` is `False` (the default), background is combined and a list of $3$ $?_i \\times M$ `numpy` arrays are returned,\n",
    "        containing bin edges (partitioning $[0,1]$), signal bin contents, and background bin contents.\n",
    "        \n",
    "        If `sepbg` is `True`, backgrounds are differentiatedlist of $2 +$ `num_bgs` $?_i \\times M$ `numpy` arrays are returned,\n",
    "        containing bin edges (partitioning $[0,1]$), signal bin contents, and `self.num_bgs` background bin contents.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        \n",
    "        preds = preds if preds is not None else self.test_preds\n",
    "        labels = labels if labels is not None else self.test_labels\n",
    "        predictions = self.predict_proba(preds)\n",
    "        sig_bins, bin_edges = np.histogram(predictions[labels==1], bins=num_bins, density=True)\n",
    "        sig_bins *= sig_norm\n",
    "        if sepbg:\n",
    "            bg_norms = bg_norm\n",
    "            bg_binss = [\n",
    "                bg_norm * np.histogram(predictions[labels==-i], bins=num_bins, density=True)[0] \n",
    "                for i, bg_norm in enumerate(bg_norms)]\n",
    "            if dataframe:\n",
    "                return pd.DataFrame(data=[bin_edges, sig_bins] + bg_binss, columns=['Bin Edges', 'Signal'] + ['Background {}'.format(i) for i in range(1, self.num_bgs+1)])\n",
    "            else:\n",
    "                return [bin_edges, sig_bins] + bg_binss\n",
    "        else:\n",
    "            bg_bins = np.histogram(predictions[labels!=1], bins=num_bins, density=True)\n",
    "            if dataframe:\n",
    "                return pd.DataFrame(data=[bin_edges, sig_bins, bg_bins], columns=['Bin Edges', 'Signal', 'Background'])\n",
    "            else:\n",
    "                return [bin_edges, sig_bins, bg_bins]\n",
    "            \n",
    "    def feature_importance(model):\n",
    "        \"\"\"\n",
    "        Returns the importance of the $M$ features used to train the `model` argument.\n",
    "        \"\"\"\n",
    "        return model.feature_importances_\n",
    "    \n",
    "    def sorted_feature_importance(features, importances):\n",
    "        \"\"\"\n",
    "        Returns list of features sorted by importance.\n",
    "        \n",
    "        Given arguments `features` and `importances`, lists of length $M$, returns list of size $M \\times 2$ where\n",
    "        the first column gives features and the second their associated importances, sorted by importance.\n",
    "        \"\"\"\n",
    "        ranked_indices = np.argsort(-np.abs(importances))\n",
    "        return [[features[i], importances[i]] for i in ranked_indices]\n",
    "        \n",
    "    def accuracy(self, preds=None, labels=None, threshold=None):\n",
    "        r\"\"\"\n",
    "        Computes model accuracy on a dataset ($? x M$ predictors, length $?$ labels).\n",
    "        \n",
    "        Returns value in $[0,1]$ giving model accuracy on the provided predictors and labels.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        preds = preds if preds is not None else self.test_preds\n",
    "        labels = labels if labels is not None else self.test_labels\n",
    "        predictions = self.predict(preds=preds, threshold=threshold)\n",
    "        return len(preds) - np.sum(np.abs(predictions - labels)) / len(preds)\n",
    "        \n",
    "    def conf_matrix(self, predictions=None, labels=None):\n",
    "        r\"\"\"\n",
    "        Computes the confusion matrix of the trained model on a dataset ($? x M$ predictors, length $?$ labels).\n",
    "        \n",
    "        Returns $2 \\times 2$ confusion matrix using `sklearn.metrics.confusion_matrix`.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        predictions = predictions if predictions is not None else self.predict(self.test_preds)\n",
    "        labels = labels if np.any(labels) is not None else self.test_labels\n",
    "        return skm.confusion_matrix(labels, predictions, labels=[0,1])\n",
    "    \n",
    "    def tpr_cm(self, conf_matrix):\n",
    "        \"\"\"\n",
    "        Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
    "        of a trained model given a confusion matrix.\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return conf_matrix[1,1]/np.sum(conf_matrix[1])\n",
    "        \n",
    "    def fpr_cm(self, conf_matrix):\n",
    "        \"\"\"\n",
    "        Computes the false positive rate (fpr; misidentified background/total background) \n",
    "        of a trained model given a confusion matrix.\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \"\"\"\n",
    "        return conf_matrix[0,1]/np.sum(conf_matrix[0])\n",
    "    \n",
    "    def tpr(self, predictions=None, labels=None):\n",
    "        r\"\"\"\n",
    "        Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
    "        of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \n",
    "        If `predictions` aren't provided, `self.predict(self.test_preds)` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        predictions = predictions if predictions is not None else self.predict(self.test_preds)\n",
    "        labels = labels if labels is not None else self.test_labels\n",
    "        return self.tpr_cm(self.conf_matrix(predictions, labels))\n",
    "    \n",
    "    def fpr(self, predictions=None, labels=None):\n",
    "        r\"\"\"\n",
    "        Computes the false positive rate (fpr; misidentified background/total background) \n",
    "        of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
    "        \n",
    "        Returns value in $[0,1]$.\n",
    "        \n",
    "        If `predictions` aren't provided, `self.predict(self.test_preds)` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \"\"\"\n",
    "        predictions = predictions if predictions is not None else self.predict(self.test_preds)\n",
    "        labels = labels if labels is not None else self.test_labels\n",
    "        return self.fpr_cm(self.conf_matrix(predictions, labels))\n",
    "    \n",
    "    def significance(self, signal, background, tpr=None, fpr=None, sepbg=False):\n",
    "        r\"\"\"\n",
    "        Computes signal significance of a trained model given signal and background yield.\n",
    "        \n",
    "        Returns a positive real number computed by \n",
    "        $$\\frac{S \\cdot TPR}{\\sqrt{S \\cdot TPR + B \\cdot FPR}}$$\n",
    "        which corresponds to signal significance after selecting only datapoints the model identifies as signal.\n",
    "        \n",
    "        If `sepbg` is `False`, `background` should be a single real number and is multiplied by `fpr`. If `sepbg` is `True`,\n",
    "        `background` should be a list of length `self.num_bgs` where the $i$th element contains background yield of the $i$th\n",
    "        background type. `fpr`, if passed, is then also a list of length `self.num_bgs` giving false positive rates for each\n",
    "        of the background types.\n",
    "        \n",
    "        If `tpr` isn't provided, `self.tpr()` is used. \n",
    "        If `fpr` isn't provided, `self.fpr()` or a list of false positive rates coming from `self.test_bgs`\n",
    "        are used, depending on the value of `sepbg`. \n",
    "        \"\"\"\n",
    "        tpr = tpr if tpr is not None else self.tpr()\n",
    "        if sepbg:\n",
    "            fprs = fpr if fpr is not None else [\n",
    "                self.fpr(self.predict(pred), label) for pred, label in zip(\n",
    "                    self.test_bgs_preds, np.zeros(np.sum([len(x) for x in self.test_bgs_preds])))]\n",
    "            fprXbackground = np.sum(np.multiply(fprs, background), axis=-1)\n",
    "            return signal * tpr / np.sqrt(signal * tpr + fprXbackground + 1e-10)\n",
    "        else:\n",
    "            fpr = fpr if fpr is not None else self.fpr()\n",
    "            return signal * tpr / np.sqrt(signal * tpr + background * fpr + 1e-10)\n",
    "    \n",
    "    def newvar2thresh(self, newvar):\n",
    "        r\"\"\"\n",
    "        Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
    "        performing change of variables from `newvar` to `threshold`\n",
    "        \n",
    "        In particular, threshold $= 1 - 10^{\\text{newvar}}$\n",
    "        \"\"\"\n",
    "        \n",
    "        return 1 - np.power(10, newvar)\n",
    "    \n",
    "    def thresh2newvar(self, thresh):\n",
    "        r\"\"\"\n",
    "        Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
    "        performing change of variables from `threshold` to `newvar`\n",
    "        \n",
    "        In particular, newvar $= \\log_{10}(1 - \\text{threhold})$\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.log10(1 - thresh)\n",
    "    \n",
    "    def max_allowable_threshold(self, preds=None, labels=None):\n",
    "        \"\"\"\n",
    "        Returns the highest threshold such that only labelling elements of `self.test_pred` with predicted\n",
    "        probabilities higher than that threshold as signal still yields 25 signal.\n",
    "        \n",
    "        To achieve a discovery potential of $5\\sigma$, even in the best case scenario ($TPR = 1, FPR = 0$) we still\n",
    "        require $5^2 = 25$ signal events, hence we cannot chose a threshold so high that we do not keep at least\n",
    "        25 signal events.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        \n",
    "        NOTE: this function frequently returns an extrapolation error as $25$ frequently falls outside of the \n",
    "        function interpolation range (i.e., to achieve less than 25 signal events requires coming extremely close to $1$).\n",
    "        \"\"\"\n",
    "        \n",
    "        preds = preds if preds is not None else self.test_preds\n",
    "        labels = labels if labels is not None else self.test_labels\n",
    "        newvars = np.concatenate((np.linspace(-8, -2, 10, endpoint=False), np.linspace(-2, 0, 51, endpoint=False)))\n",
    "        probs = self.model.predict_proba(preds)[:,1]\n",
    "        predicts = np.array(\n",
    "            [np.where(probs > self.newvar2thresh(newvar),\n",
    "                      np.ones_like(probs), np.zeros_like(probs)) for newvar in newvars])\n",
    "        num_sig = [np.sum(predict[(predict == 1) & (labels == 1)]) for predict in predicts]\n",
    "        f = scipy.interpolate.interp1d(num_sig, newvars, kind='cubic')\n",
    "        return self.newvar2thresh(f(25))\n",
    "    \n",
    "    def get_tprs_fprs(self, preds=None, labels=None, sepbg=False):\n",
    "        \"\"\"\n",
    "        Produces (true positive rate, false positive rate) pairs for various thresholds \n",
    "        for the trained model on data sets.\n",
    "        \n",
    "        If `sepbg` is `True`, background is combined and a list of length $4$ is returned containing a list of $L$ sampled\n",
    "        newvars (a convenient change of variable to approach arbitrarily close to 1: related to thresholds by \n",
    "        `bcml_model.newvar2thresh()`), an $L$-list of tprs associated to those thresholds, an $L$-list of fprs \n",
    "        related to those thresholds, and an $L$-list of length $?$ `numpy` arrays giving the predicted signal probabilities\n",
    "        for the given data set.\n",
    "        \n",
    "        If `sepbg` is `Frue`, background is split and a list of length $4$ `self.num_bgs` is returned containing a \n",
    "        list of $L$ sampled newvars, an $L$-list of tprs associated to those thresholds, an $L$-list of lists of length\n",
    "        `self.num_bgs` containing fprs for each background type for each threshold, and an $L$-list of length $?$ \n",
    "        `numpy` arrays giving the predicted signal probabilities for the given data set.\n",
    "        \n",
    "        If predictors `preds` aren't provided, `self.test_preds` is used. \n",
    "        If `labels` aren't provided, `self.test_labels` is used.\n",
    "        Changes are made to both of the above depending on the value of `sepbg`.\n",
    "        \"\"\"\n",
    "        \n",
    "        # setting up variables\n",
    "        preds = preds if preds is not None else ([self.test_sigs_preds] + self.test_bgs_preds if sepbg else self.test_preds)\n",
    "        labels = labels if labels is not None else ([np.ones_like(preds[0][:,0])] + [np.zeros_like(bg_preds[:,0]) for bg_preds in preds[1:]] if sepbg else self.test_labels)\n",
    "        min_newvar, max_newvar = [-8, 0]\n",
    "        newvars = np.concatenate((np.linspace(min_newvar, -2, 10, endpoint=False), np.linspace(-2, max_newvar, 51, endpoint=False)))\n",
    "        \n",
    "        # computing significance as a function of threshold\n",
    "        if sepbg:\n",
    "            predss = preds\n",
    "            labelss = labels\n",
    "            probss = [self.predict_proba(preds) for preds in predss]\n",
    "            predictionsss = np.array(\n",
    "                [[np.where(probs > self.newvar2thresh(newvar), \n",
    "                          np.ones_like(probs), np.zeros_like(probs)) for probs in probss] for newvar in newvars])\n",
    "            sig_conf_matrices = [\n",
    "                self.conf_matrix(predictions=predictionss[0], labels=labelss[0]) for predictionss in predictionsss]\n",
    "            bg_conf_matricess = [\n",
    "                [self.conf_matrix(predictions=predictions, labels=labelss[i+1]) for i, predictions in enumerate(predictionss[1:])] for predictionss in predictionsss]\n",
    "            tprs = np.array([self.tpr_cm(conf_matrix) for conf_matrix in sig_conf_matrices])\n",
    "            fprss = np.array([[self.fpr_cm(conf_matrix) for conf_matrix in conf_matrices] for conf_matrices in bg_conf_matricess])\n",
    "            return [newvars, tprs, fprss, probss]\n",
    "        else:\n",
    "            probs = self.predict_proba(preds)\n",
    "            predictionss = np.array(\n",
    "                [np.where(probs > self.newvar2thresh(newvar), \n",
    "                          np.ones_like(probs), np.zeros_like(probs)) for newvar in newvars])\n",
    "            conf_matrices = [self.conf_matrix(predictions=predictions, labels=labels) for predictions in predictionss]\n",
    "            tprs = [self.tpr_cm(conf_matrix) for conf_matrix in conf_matrices]\n",
    "            fprs = [self.fpr_cm(conf_matrix) for conf_matrix in conf_matrices]\n",
    "            return [newvars, tprs, fprs, probs]\n",
    "        \n",
    "    def best_threshold(self, signal, background, preds=None, labels=None, sepbg=False):\n",
    "        \"\"\"\n",
    "        Optimizes the threshold on a given data set ($? x M$ predictors, length $?$ labels).\n",
    "        \"\"\"\n",
    "        \n",
    "        preds = preds if preds is not None else ([self.test_sigs_preds] + self.test_bgs_preds if sepbg else self.test_preds)\n",
    "        labels = labels if labels is not None else ([np.ones_like(preds[0][:,0])] + [np.zeros_like(bg_preds[:,0]) for bg_preds in preds[1:]] if sepbg else self.test_labels)\n",
    "        newvars, tprs, fprs, probs = self.get_tprs_fprs(preds, labels, sepbg)\n",
    "        significances = -self.significance(signal, background, tprs, fprs, sepbg=sepbg)\n",
    "\n",
    "        # interpolating significance as a function of threshold, then maximizing\n",
    "        f = scipy.interpolate.interp1d(newvars, significances, kind='cubic')\n",
    "        res = scipy.optimize.minimize(f, [-2], bounds=[(newvars[0] + 1e-1, newvars[-1] - 1e-1)])\n",
    "        \n",
    "        # computing significance, tpr, fpr for optimized threshold\n",
    "        best_threshold = self.newvar2thresh(res.x[0])\n",
    "        if sepbg:\n",
    "            probss = probs\n",
    "            labelss = labels\n",
    "            fprss = fprs\n",
    "            best_predictss = [np.where(probs > best_threshold, np.ones_like(probs), np.zeros_like(probs)) for probs in probss]\n",
    "            sig_conf_matrix = self.conf_matrix(predictions=best_predictss[0], labels=labelss[0])\n",
    "            bg_conf_matrices = [self.conf_matrix(predictions=best_predicts, labels=labelss[i+1]) for i, best_predicts in enumerate(best_predictss[1:])]\n",
    "            tpr = self.tpr_cm(sig_conf_matrix)\n",
    "            fprs = [self.fpr_cm(conf_matrix) for conf_matrix in bg_conf_matrices]\n",
    "            best_sig = self.significance(signal, background, tpr, fprs, sepbg=sepbg)\n",
    "            return [best_threshold, best_sig, tpr, fprs, tprs, fprss]\n",
    "        else:\n",
    "            best_predictss = np.where(probs > best_threshold, np.ones_like(probs), np.zeros_like(probs))\n",
    "            conf_matrix = self.conf_matrix(predictions=best_predict)\n",
    "            tpr = self.tpr_cm(conf_matrix)\n",
    "            fpr = self.fpr_cm(conf_matrix)\n",
    "            best_sig = self.significance(signal, background, tpr, fpr, sepbg=sepbg)\n",
    "            return [best_threshold, best_sig, tpr, fpr, tprs, fprs]\n",
    "    \n",
    "    def req_sig_cs(self, lumi, bg_cs, tpr, fpr, sig=5, sepbg=False):\n",
    "        \"\"\"\n",
    "        Given a luminosity (in fb$^{-1}$), a background cross section (in pb), a true positive rate, a false positive rate,\n",
    "        and a signal significance, computes the signal cross section required for the signal significance to be achieved.\n",
    "        \n",
    "        If `sepbg` is False, background is combined and a single FPR is used; if `sepbg` is True, it is assumed that\n",
    "        `bg_cs`, `fpr` are each lists of length `self.num_bgs` and their vector dot product is used for background yield.\n",
    "        \"\"\"\n",
    "        \n",
    "        conv = 10**15 / 10**12\n",
    "        if sepbg:\n",
    "            bg = np.sum(np.multiply(bg_cs, fpr))\n",
    "            coef = [-tpr**2 * lumi**2 * conv**2, sig**2 * tpr * lumi * conv, sig**2 * bg * lumi * conv]\n",
    "        else:\n",
    "            coef = [-tpr**2 * lumi**2 * conv**2, sig**2 * tpr * lumi * conv, sig**2 * fpr * bg_cs * lumi * conv]\n",
    "        return np.amax(np.roots(coef))\n",
    "        \n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the model to `filename.joblib`\n",
    "        \"\"\"\n",
    "        joblib.dump(self.model, filename + '.joblib')\n",
    "        \n",
    "    def refresh_model(model):\n",
    "        \"\"\"\n",
    "        If this class gets updated, run this function on your already trained model to have it reflect the updated\n",
    "        class without retraining being necessary.\n",
    "        \"\"\"\n",
    "        return sigbg_model(model.model, model.train, model.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting up and running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a `bcml_model` instance\n",
    "\n",
    "To create a new `bcml_model` instance, three things are required. \n",
    "\n",
    "First, you need `model`, a machine learning binary classification model: this library was designed to work with `scikit-learn` classifiers, such as `sklearn.linear_model.LogisticRegression`, `sklearn.ensemble.RandomForestClassifier`, or `sklearn.ensemble.GradientBoostingClassifier`.\n",
    "\n",
    "Second, you need `train`, a training data set. This should be a `numpy` array of shape $N \\times (M + 1)$ if you have $N$ training data points and $M$ features. The first $M$ columns of `train` should contain your features, while the final column is your label: $1$ denotes signal, while $0$ or a strictly negative integer denotes background. Negative integers can be used to denote different kinds of background: i.e., $-2$ would denote the background of type $2$.\n",
    "\n",
    "Third, you need `test`, a testing data set. This should be a `numpy` array of shape $N' \\times (M + 1)$ formatted the same as `train`. Typically, $N' \\approx \\frac{1}{3}N$.\n",
    "\n",
    "If you utilize the negative integer labelling of background data points, you should pass `num_bgs` as well, denoting the number of different backgrounds you're using (i.e., your backgrounds labels $\\ell_i$ satisfy $-$ `num_bgs` $\\leq \\ell_i \\leq -1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes of `bcml_model`\n",
    "\n",
    "In addition to the arguments passed, a `bcml_model` instance has the following attributes.\n",
    "\n",
    "`train_preds`: training predictors, $N \\times M$ `numpy` array, the first $M$ columns of train.\n",
    "\n",
    "`train_labels`: training labels, `numpy` array of length $N$, final column of train (with negative integers mapped to $0$)\n",
    "\n",
    "`test_preds`: test predictors, $N' \\times M$ `numpy` array, first $M$ columns of test\n",
    "\n",
    "`test_labels`: test labels, `numpy` array of length $N'$, final column of test (with negative integers mapped to $0$)\n",
    "\n",
    "`test_bgs`: background test data split by background, list of $N_i \\times (M + 1)$ `numpy` arrays such that the $i$th element contains all test data points of background type $i$ (i.e., $1 \\leq i \\leq$ `num_bgs` and $\\sum_i N_i = N' - $ # of signal data points)\n",
    "\n",
    "`test_bgs_preds`: background test predictors split by background, list of $N_i \\times M$ `numpy` arrays\n",
    "\n",
    "`test_sigs`: signal test data, $\\overline{N} \\times (M + 1)$ `numpy` array (i.e., $\\overline{N} + \\sum_i N_i = N'$)\n",
    "\n",
    "`test_sigs_preds`: signal test data predictors, $\\overline{N} \\times M$ `numpy` array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fit\" class=\"doc_header\"><code>bcml_model.fit</code><a href=\"__main__.py#L21\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fit</code>(**`preds`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Fits `model` to data.\n",
       "\n",
       "If predictors `preds` and labels `labels` aren't provided, \n",
       "`self.train_preds` and `self.train_labels` are used, respectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict_proba\" class=\"doc_header\"><code>bcml_model.predict_proba</code><a href=\"__main__.py#L32\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict_proba</code>(**`preds`**=*`None`*)\n",
       "\n",
       "Predicts signal probability for each element of a dataset ($? \\times M$ `numpy` array).\n",
       "\n",
       "Returns `numpy` array of length $M$ with values in $[0,1]$ giving predicted signal probabilities.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "Uses the `predict_proba` method built into `scikit-learn` models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict\" class=\"doc_header\"><code>bcml_model.predict</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict</code>(**`preds`**=*`None`*, **`threshold`**=*`None`*)\n",
       "\n",
       "Predicts signal ($1$) or background ($2$) for each element of a dataset ($?     imes M$ `numpy` array).\n",
       "\n",
       "Returns `numpy` array of length $M$ with values in $\\{0,1\\}$ giving predicted classifications. \n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used.\n",
       "Uses the `predict` method built into `scikit-learn` models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.predict_hist\" class=\"doc_header\"><code>bcml_model.predict_hist</code><a href=\"__main__.py#L66\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.predict_hist</code>(**`preds`**=*`None`*, **`labels`**=*`None`*, **`num_bins`**=*`100`*, **`sepbg`**=*`False`*, **`sig_norm`**=*`1`*, **`bg_norm`**=*`1`*, **`dataframe`**=*`False`*)\n",
       "\n",
       "Constructs a histogram of predicted signal probabilities for signal and background constituents of \n",
       "a dataset ($? \\times M$ `numpy` array).\n",
       "\n",
       "If `sepbg` is `False` (the default), background is combined and a list of $3$ $?_i \\times M$ `numpy` arrays are returned,\n",
       "containing bin edges (partitioning $[0,1]$), signal bin contents, and background bin contents.\n",
       "\n",
       "If `sepbg` is `True`, backgrounds are differentiatedlist of $2 +$ `num_bgs` $?_i \\times M$ `numpy` arrays are returned,\n",
       "containing bin edges (partitioning $[0,1]$), signal bin contents, and `self.num_bgs` background bin contents.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.predict_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.feature_importance\" class=\"doc_header\"><code>bcml_model.feature_importance</code><a href=\"__main__.py#L102\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.feature_importance</code>(**`model`**)\n",
       "\n",
       "Returns the importance of the $M$ features used to train the `model` argument."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.sorted_feature_importance\" class=\"doc_header\"><code>bcml_model.sorted_feature_importance</code><a href=\"__main__.py#L108\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.sorted_feature_importance</code>(**`features`**, **`importances`**)\n",
       "\n",
       "Returns list of features sorted by importance.\n",
       "\n",
       "Given arguments `features` and `importances`, lists of length $M$, returns list of size $M      imes 2$ where\n",
       "the first column gives features and the second their associated importances, sorted by importance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.sorted_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.accuracy\" class=\"doc_header\"><code>bcml_model.accuracy</code><a href=\"__main__.py#L118\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.accuracy</code>(**`preds`**=*`None`*, **`labels`**=*`None`*, **`threshold`**=*`None`*)\n",
       "\n",
       "Computes model accuracy on a dataset ($? x M$ predictors, length $?$ labels).\n",
       "\n",
       "Returns value in $[0,1]$ giving model accuracy on the provided predictors and labels.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.conf_matrix\" class=\"doc_header\"><code>bcml_model.conf_matrix</code><a href=\"__main__.py#L132\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.conf_matrix</code>(**`predictions`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Computes the confusion matrix of the trained model on a dataset ($? x M$ predictors, length $?$ labels).\n",
       "\n",
       "Returns $2 \\times 2$ confusion matrix using `sklearn.metrics.confusion_matrix`.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.tpr_cm\" class=\"doc_header\"><code>bcml_model.tpr_cm</code><a href=\"__main__.py#L145\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.tpr_cm</code>(**`conf_matrix`**)\n",
       "\n",
       "Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
       "of a trained model given a confusion matrix.\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.tpr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fpr_cm\" class=\"doc_header\"><code>bcml_model.fpr_cm</code><a href=\"__main__.py#L154\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fpr_cm</code>(**`conf_matrix`**)\n",
       "\n",
       "Computes the false positive rate (fpr; misidentified background/total background) \n",
       "of a trained model given a confusion matrix.\n",
       "\n",
       "Returns value in $[0,1]$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fpr_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.tpr\" class=\"doc_header\"><code>bcml_model.tpr</code><a href=\"__main__.py#L163\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.tpr</code>(**`predictions`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Computes the true positive rate (tpr; correctly identified signal/total signal) \n",
       "of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
       "\n",
       "Returns value in $[0,1]$.\n",
       "\n",
       "If `predictions` aren't provided, `self.predict(self.test_preds)` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.fpr\" class=\"doc_header\"><code>bcml_model.fpr</code><a href=\"__main__.py#L177\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.fpr</code>(**`predictions`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Computes the false positive rate (fpr; misidentified background/total background) \n",
       "of a trained model given predictions and labels (both `numpy` array of length $?$ with values in $\\{0,1\\}$)\n",
       "\n",
       "Returns value in $[0,1]$.\n",
       "\n",
       "If `predictions` aren't provided, `self.predict(self.test_preds)` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenomenology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.significance\" class=\"doc_header\"><code>bcml_model.significance</code><a href=\"__main__.py#L191\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.significance</code>(**`signal`**, **`background`**, **`tpr`**=*`None`*, **`fpr`**=*`None`*, **`sepbg`**=*`False`*)\n",
       "\n",
       "Computes signal significance of a trained model given signal and background yield.\n",
       "\n",
       "Returns a positive real number computed by \n",
       "$$\\frac{S \\cdot TPR}{\\sqrt{S \\cdot TPR + B \\cdot FPR}}$$\n",
       "which corresponds to signal significance after selecting only datapoints the model identifies as signal.\n",
       "\n",
       "If `sepbg` is `False`, `background` should be a single real number and is multiplied by `fpr`. If `sepbg` is `True`,\n",
       "`background` should be a list of length `self.num_bgs` where the $i$th element contains background yield of the $i$th\n",
       "background type. `fpr`, if passed, is then also a list of length `self.num_bgs` giving false positive rates for each\n",
       "of the background types.\n",
       "\n",
       "If `tpr` isn't provided, `self.tpr()` is used. \n",
       "If `fpr` isn't provided, `self.fpr()` or a list of false positive rates coming from `self.test_bgs`\n",
       "are used, depending on the value of `sepbg`. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.newvar2thresh\" class=\"doc_header\"><code>bcml_model.newvar2thresh</code><a href=\"__main__.py#L219\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.newvar2thresh</code>(**`newvar`**)\n",
       "\n",
       "Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
       "performing change of variables from `newvar` to `threshold`\n",
       "\n",
       "In particular, threshold $= 1 - 10^{\\text{newvar}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.newvar2thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.thresh2newvar\" class=\"doc_header\"><code>bcml_model.thresh2newvar</code><a href=\"__main__.py#L229\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.thresh2newvar</code>(**`thresh`**)\n",
       "\n",
       "Helper method for `bcml.max_allowable_threshold()`, `bcml.get_tprs_fprs()`, and `bcml.best_threshold()`, \n",
       "performing change of variables from `threshold` to `newvar`\n",
       "\n",
       "In particular, newvar $= \\log_{10}(1 - \\text{threhold})$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.thresh2newvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.max_allowable_threshold\" class=\"doc_header\"><code>bcml_model.max_allowable_threshold</code><a href=\"__main__.py#L239\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.max_allowable_threshold</code>(**`preds`**=*`None`*, **`labels`**=*`None`*)\n",
       "\n",
       "Returns the highest threshold such that only labelling elements of `self.test_pred` with predicted\n",
       "probabilities higher than that threshold as signal still yields 25 signal.\n",
       "\n",
       "To achieve a discovery potential of $5\\sigma$, even in the best case scenario ($TPR = 1, FPR = 0$) we still\n",
       "require $5^2 = 25$ signal events, hence we cannot chose a threshold so high that we do not keep at least\n",
       "25 signal events.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used.\n",
       "\n",
       "NOTE: this function frequently returns an extrapolation error as $25$ frequently falls outside of the \n",
       "function interpolation range (i.e., to achieve less than 25 signal events requires coming extremely close to $1$)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.max_allowable_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.get_tprs_fprs\" class=\"doc_header\"><code>bcml_model.get_tprs_fprs</code><a href=\"__main__.py#L266\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.get_tprs_fprs</code>(**`preds`**=*`None`*, **`labels`**=*`None`*, **`sepbg`**=*`False`*)\n",
       "\n",
       "Produces (true positive rate, false positive rate) pairs for various thresholds \n",
       "for the trained model on data sets.\n",
       "\n",
       "If `sepbg` is `True`, background is combined and a list of length $4$ is returned containing a list of $L$ sampled\n",
       "newvars (a convenient change of variable to approach arbitrarily close to 1: related to thresholds by \n",
       "[`bcml_model.newvar2thresh()`](/bcml4pheno/bcml_model.html#bcml_model.newvar2thresh())), an $L$-list of tprs associated to those thresholds, an $L$-list of fprs \n",
       "related to those thresholds, and an $L$-list of length $?$ `numpy` arrays giving the predicted signal probabilities\n",
       "for the given data set.\n",
       "\n",
       "If `sepbg` is `Frue`, background is split and a list of length $4$ `self.num_bgs` is returned containing a \n",
       "list of $L$ sampled newvars, an $L$-list of tprs associated to those thresholds, an $L$-list of lists of length\n",
       "`self.num_bgs` containing fprs for each background type for each threshold, and an $L$-list of length $?$ \n",
       "`numpy` arrays giving the predicted signal probabilities for the given data set.\n",
       "\n",
       "If predictors `preds` aren't provided, `self.test_preds` is used. \n",
       "If `labels` aren't provided, `self.test_labels` is used.\n",
       "Changes are made to both of the above depending on the value of `sepbg`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.get_tprs_fprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.best_threshold\" class=\"doc_header\"><code>bcml_model.best_threshold</code><a href=\"__main__.py#L318\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.best_threshold</code>(**`signal`**, **`background`**, **`preds`**=*`None`*, **`labels`**=*`None`*, **`sepbg`**=*`False`*)\n",
       "\n",
       "Optimizes the threshold on a given data set ($? x M$ predictors, length $?$ labels)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.req_sig_cs\" class=\"doc_header\"><code>bcml_model.req_sig_cs</code><a href=\"__main__.py#L353\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.req_sig_cs</code>(**`lumi`**, **`bg_cs`**, **`tpr`**, **`fpr`**, **`sig`**=*`5`*, **`sepbg`**=*`False`*)\n",
       "\n",
       "Given a luminosity (in fb$^{-1}$), a background cross section (in pb), a true positive rate, a false positive rate,\n",
       "and a signal significance, computes the signal cross section required for the signal significance to be achieved.\n",
       "\n",
       "If `sepbg` is False, background is combined and a single FPR is used; if `sepbg` is True, it is assumed that\n",
       "`bg_cs`, `fpr` are each lists of length `self.num_bgs` and their vector dot product is used for background yield."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.req_sig_cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.save_model\" class=\"doc_header\"><code>bcml_model.save_model</code><a href=\"__main__.py#L370\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.save_model</code>(**`filename`**)\n",
       "\n",
       "Saves the model to `filename.joblib`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bcml_model.refresh_model\" class=\"doc_header\"><code>bcml_model.refresh_model</code><a href=\"__main__.py#L376\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bcml_model.refresh_model</code>(**`model`**)\n",
       "\n",
       "If this class gets updated, run this function on your already trained model to have it reflect the updated\n",
       "class without retraining being necessary."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bcml_model.refresh_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
